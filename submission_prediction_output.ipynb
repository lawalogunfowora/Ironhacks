{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IronHacks Submission Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "---\n",
    "\n",
    "In this project, the aim is to make a prediction of foot traffic for week 44 (Since Indiana recorded first COVID-19 case) in 1804 Point of Interests (POIs) in Tippecanoe County in Indiana, United States of America (a regression task). The data that is being used has been collected from the week 1 to week 43 and has is available as a BIgQuery project file. The schema of the tables that will be used for this project can be found [here](https://docs.google.com/spreadsheets/d/e/2PACX-1vQUgT-CyXoPO6Fa4r4YlwF6uqHMvcqiWM4UNlUqYNdrljntzZsL8sU9-BIZZIOdd_CO3W5ILB_MW4TW/pubhtml).\n",
    "\n",
    "To start with, the six tables would be imported from the BigQuery project and stored as a pandas DataFrame. Then, Exploratory Data Analysis (EDA) would be carried out on the data to better understand their relationships for feature selection for the modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%logstop\n",
    "%logstart -t -r -q ipython_command_log.py global\n",
    "\n",
    "#- IRONHACKS RESEARCH TRACKING CODE\n",
    "#----------------------------------\n",
    "# The following code is used to help our research team understand how you \n",
    "# our notebook environment. We do not collect any personal information with\n",
    "# the following code, it is used to measure when and how often you work on\n",
    "# your submission files.\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import IPython.core.history as history\n",
    "\n",
    "ha = history.HistoryAccessor()\n",
    "ha_tail = ha.get_tail(1)\n",
    "ha_cmd = next(ha_tail)\n",
    "session_id = str(ha_cmd[0])\n",
    "command_id = str(ha_cmd[1])\n",
    "timestamp = datetime.utcnow().isoformat()\n",
    "history_line = ','.join([session_id, command_id, timestamp]) + '\\n'\n",
    "logfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\n",
    "logfile.write(history_line)\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from catboost import CatBoostRegressor \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "import os\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='keys.json'   #using unique key to get access to the data \n",
    "bigquery_client = bigquery.Client(project='ironhacks-covid19-data')\n",
    "bigquery_client\n",
    "bigquery_client = bigquery.Client()\n",
    "\n",
    "def table_pandas(table):  #function to convert the six tables to pandas DataFrame\n",
    "    QUERY = \"\"\"\n",
    "\n",
    "    SELECT *\n",
    "    FROM ironhacks-covid19-data.ironhacks_covid19_competition.{i}\n",
    "\n",
    "    \"\"\".format(i=table)\n",
    "\n",
    "    query_job = bigquery_client.query(QUERY)\n",
    "    return query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = table_pandas('weekly_patterns')\n",
    "mobility = table_pandas('mobility_graph')\n",
    "social_distancing = table_pandas('cbg_social_distancing')\n",
    "covid_cases = table_pandas('covid19_cases')\n",
    "executive_orders = table_pandas('executive_orders')\n",
    "predict_table = table_pandas('prediction_list_poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = table_pandas('weekly_patterns')\n",
    "predict_table = table_pandas('prediction_list_poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases = table_pandas('covid19_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility = table_pandas('mobility_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "With an aim to get further understand the available data and know which of features to use in modeling, each table will be explored in the next couple of cells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_head (table):   #function for getting familiar with the table\n",
    "    return table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_number</th>\n",
       "      <th>start_date</th>\n",
       "      <th>county</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Tippecanoe</td>\n",
       "      <td>18157</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>Tippecanoe</td>\n",
       "      <td>18157</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>Tippecanoe</td>\n",
       "      <td>18157</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>Tippecanoe</td>\n",
       "      <td>18157</td>\n",
       "      <td>278</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>Tippecanoe</td>\n",
       "      <td>18157</td>\n",
       "      <td>352</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week_number  start_date      county   fips  cases  deaths\n",
       "0           11  2020-03-16  Tippecanoe  18157      7       0\n",
       "1           12  2020-03-23  Tippecanoe  18157     46       3\n",
       "2           13  2020-03-30  Tippecanoe  18157    148       7\n",
       "3           14  2020-04-06  Tippecanoe  18157    278       7\n",
       "4           15  2020-04-13  Tippecanoe  18157    352      12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_head(covid_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1803"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mobility['poi_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_head(predict_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with The Primary Data\n",
    "For a start, the main_data will be pre-processed for the modeling and used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = main_data.copy()\n",
    "\n",
    "x['date_start'] =  pd.to_datetime(x['date_start'], format='%Y-%m-%d') #convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dayofweek'] = pd.DatetimeIndex(x['date_start']).dayofweek\n",
    "x['is_weekend'] = x.dayofweek.isin([5,6])*1\n",
    "x['quarter'] = x['date_start'].dt.quarter\n",
    "x['month'] = x['date_start'].dt.month\n",
    "x['day'] = x['date_start'].dt.day\n",
    "x['weekofyear'] = x['date_start'].dt.weekofyear\n",
    "x['yearday'] = x['date_start'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_poi = x['poi_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "x.set_index('poi_id', inplace=True)\n",
    "# features = x[['week_number', 'dayofweek', 'is_weekend', 'quarter', 'month', 'day', 'weekofyear', 'yearday', 'raw_visit_counts']]\n",
    "target = x['raw_visit_counts']\n",
    "x.drop(columns=['raw_visit_counts', 'date_start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transform of target\n",
    "target = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing values (brands, top_category and NAICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop('brands', axis=1, inplace=True)  #droping since a significant number is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype({'NAICS' : 'float64'})  #convert NAICS to float format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the null values with the mode\n",
    "x['NAICS'].fillna(x['NAICS'].mode()[0], inplace=True)\n",
    "\n",
    "x['top_category'].fillna(x['top_category'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  4,  5,  7,  9, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_features_index=np.where(x.dtypes != float) [0] \n",
    "cate_features_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_regressor(features, target):\n",
    "    \"\"\"\n",
    "    Function to model the foot traffic time series data.\n",
    "    It uses CatBoost Regressor model for forecasting.\n",
    "    \n",
    "    Returns\n",
    "        forecasts (float):  Forecast value for the next time step in the series\n",
    "        y (int): True value to be compared with the forecasted value\n",
    "    \"\"\"    \n",
    "    \n",
    "    y = target.shift(periods=-1)\n",
    "\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    dtregr = CatBoostRegressor()\n",
    "    dtregr.fit(features[:-2], y[:-2], cat_features=cate_features_index)\n",
    "    cat_grid = {\n",
    "        'iterations': np.arange(30, 50, 100),\n",
    "        'depth': np.arange(6, 8, 10),\n",
    "        'learning_rate': [0.01, 0.05, 0.1]\n",
    "    }\n",
    "    \n",
    "    cat_model_rs = GridSearchCV(estimator= dtregr,\n",
    "                                     param_grid=cat_grid,\n",
    "                                     cv=2,\n",
    "                                     scoring = ['neg_mean_squared_error','neg_mean_absolute_error'],\n",
    "                                     refit = 'neg_mean_absolute_error',\n",
    "                                     verbose=True)\n",
    "    \n",
    "    cat_model_rs.fit(features[:-2], y[:-2], cat_features=cate_features_index)\n",
    "\n",
    "    forecasts = cat_model_rs.predict(np.array(features.iloc[-2]).reshape(1,-1))\n",
    "    \n",
    "    return forecasts, y.iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "forecasts2 = []\n",
    "tests = []\n",
    "location_errors = []\n",
    "\n",
    "for poi in unique_poi[1802:]:\n",
    "    unique_X = x[x.index == poi]\n",
    "    unique_y = target[target.index == poi]\n",
    "#     df = weekly_patterns[weekly_patterns['poi_id'] == location]\n",
    "#     df['exec_orders'] = df['week_number'].isin(order_weeks).astype(int)\n",
    "#     try:\n",
    "    f, t = cat_regressor(unique_X, unique_y)\n",
    "    forecasts2.append(f)\n",
    "    tests.append(t)\n",
    "        \n",
    "#         if idx % 200 == 0:\n",
    "#             print(\"{} locations done.\".format(idx))\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         break;\n",
    "        \n",
    "forecasts2 = [forecast[0] for forecast in forecasts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts2 = np.expm1(forecasts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts2 = [int(np.round(i)) if i > 0 else 0 for i in forecasts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_table['poi_id'] = unique_poi\n",
    "predict_table['raw_visit_counts'] = forecasts2\n",
    "predict_table.to_csv('submission_prediction_output8.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
